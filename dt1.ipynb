{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb1403d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import fitz  # PyMuPDF library for PDF processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82990aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import filedialog\n",
    "import tkinter as tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba2e135d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = ''\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc[page_num]\n",
    "        text += page.get_text()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49150344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary_with_chatgpt(text):\n",
    "    model_name = \"gpt2\"  # or use another GPT-3 model if available\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "    input_ids = tokenizer.encode(text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    \n",
    "    # Explicitly set attention_mask and pad_token_id\n",
    "    attention_mask = input_ids != tokenizer.pad_token_id\n",
    "    model.config.pad_token_id = tokenizer.eos_token_id\n",
    "    \n",
    "    summary_ids = model.generate(\n",
    "        input_ids,\n",
    "        max_length=600,  # Adjust max_length based on your requirements\n",
    "        attention_mask=attention_mask,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        num_beams=4,\n",
    "        early_stopping=True\n",
    "    )\n",
    "\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "    input_ids = tokenizer.encode(text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    summary_ids = model.generate(input_ids, max_length=500, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5a8b322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 'bool' object has no attribute 'long'\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()  # Hide the main window\n",
    "\n",
    "    # Step 2: User uploads PDF using file dialog\n",
    "    pdf_path = filedialog.askopenfilename(title=\"Select PDF file\", filetypes=[(\"PDF files\", \"*.pdf\")])\n",
    "\n",
    "    try:\n",
    "        # Step 3: PDF Processing\n",
    "        pdf_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "        # Step 4: ChatGPT LLM Interaction and Summary Generation\n",
    "        summary = generate_summary_with_chatgpt(pdf_text)\n",
    "\n",
    "        # Step 5: Summary Output\n",
    "        print(\"\\nGenerated Summary:\")\n",
    "        print(summary)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d2c6f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Summary:\n",
      "By T. Albert\n",
      "Illustrated by: maaillustrations.com\n",
      "A Dog On A Log is just a fun story for the young \n",
      "reader. It may impart sense of rhyme and rhythm \n",
      "but is intended to evoke a smile.\n",
      "Published by Monkey Pen Ltd\n",
      "Dear Supporter, \n",
      "Thank you for downloading our children's books. \n",
      "Monkey Pen's Vision is to provide thousands of free children's \n",
      "books to young readers around the globe. \n",
      "Please share our books with your friends and family to \n",
      "support our mission. Thank you\n",
      "Please make a donation on Patreon to support\n",
      "Monkey Pens Free Book Project:\n",
      "On a beach by a tree, sat my family and me.\n",
      "Then shouted a hog, \"There's a Dog On A Log!!\"\n",
      "A Dog On A Log? Well, how can that be?\n",
      "He must be saving that big, frightening flea.\n",
      "Now why would a dog be saving a flea?\n",
      "Especially in the water on the branch of a tree. \n",
      "I couldn't believe what \n",
      "I saw happen next.\n",
      "Even that Dog On A Log was perplexed.\n",
      "The flea pulled on a rope and up came a boat.\n",
      "I'll bet you can't guess \n",
      "what happened next.\n",
      "A flea family ran from \n",
      "the dog's little toe.\n",
      "They got into the boat and began to row.\n",
      "Once on the shore, they ran through the sand.\n",
      "Over a cookie in \n",
      "my left hand.\n",
      "Right to the hog, that's \n",
      "where they went.\n",
      "They found a new home with an unpleasant scent.\n",
      "As for the Dog, he's still riding that log.\n",
      "As for me-Ouch-I think \n",
      "I have a flea.\n",
      "Your Story Book!\n",
      "A book specially made, \n",
      "with you as the main hero \n",
      "or heroine!\n",
      "Personalised children’s gifts by www.monkeypen.com\n",
      "Advertisement\n",
      "A Dog On A Log is just \n",
      "a fun story for the young \n",
      "reader. It may impart a \n",
      "sense of rhyme and rhythm \n",
      "but is intended to evoke a \n",
      "smile.\n",
      "Published by\n",
      "Illustrated by\n",
      "Please share our books with \n",
      "your friends and family to \n",
      "support our mission. Thank you\n",
      "Please make a donation on Patreon to support Monkey Pen Free Book Project:\n",
      "On a beach by a tree, sat my family and me.Then shouted a hog, \"There's a Dog On A Log!!\"A Dog On A Log? Well, how can that be?He must be saving that big, frightening flea.Even that Dog On A Log was perplexed.The flea pulled on a rope and up came a boat.I'll bet you can't guess \n",
      "what happened next.A flea family ran from \n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import fitz\n",
    "from tkinter import filedialog\n",
    "import tkinter as tk\n",
    "import torch\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = ''\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc[page_num]\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "def generate_summary_with_chatgpt(text):\n",
    "    model_name = \"gpt2\"\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "    input_ids = tokenizer.encode(text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    \n",
    "    # Create attention mask\n",
    "    attention_mask = torch.ones(input_ids.shape, dtype=torch.long)\n",
    "\n",
    "    model.config.pad_token_id = tokenizer.eos_token_id\n",
    "    \n",
    "    summary_ids = model.generate(\n",
    "        input_ids,\n",
    "        max_length=600,\n",
    "        attention_mask=attention_mask,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        num_beams=4,\n",
    "        early_stopping=True\n",
    "    )\n",
    "\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "def main():\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "\n",
    "    pdf_path = filedialog.askopenfilename(title=\"Select PDF file\", filetypes=[(\"PDF files\", \"*.pdf\")])\n",
    "\n",
    "    try:\n",
    "        pdf_text = extract_text_from_pdf(pdf_path)\n",
    "        summary = generate_summary_with_chatgpt(pdf_text)\n",
    "\n",
    "        print(\"\\nGenerated Summary:\")\n",
    "        print(summary)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ac584f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Summary:\n",
      "By T.\n",
      "\n",
      "Albert\n",
      "Illustrated by: maaillustrations.com\n",
      "A Dog On A Log is just a fun story for the young \n",
      "reader.\n",
      "\n",
      "It may impart sense of rhyme and rhythm \n",
      "but is intended to evoke a smile.\n",
      "Published by Monkey Pen Ltd\n",
      "Dear Supporter, \n",
      "Thank you for downloading our children's books.\n",
      "\n",
      "\n",
      "Monkey Pen's Vision is to provide thousands of free children's \n",
      "books to young readers around the globe.\n",
      "\n",
      "\n",
      "Please share our books with your friends and family to \n",
      "support our mission.\n",
      "\n",
      "Thank you\n",
      "Please make a donation on Patreon to support\n",
      "Monkey Pens Free Book Project:\n",
      "On a beach by a tree, sat my family and me.\n",
      "Then shouted a hog, \"There's a Dog On A Log!!\"\n",
      "A Dog On A Log? Well, how can that be?\n",
      "He must be saving that big, frightening flea.\n",
      "Now why would a dog be saving a flea?\n",
      "Especially in the water on the branch of a tree.\n",
      "\n",
      "\n",
      "I couldn't believe what \n",
      "I saw happen next.\n",
      "Even that Dog On A Log was perplexed.\n",
      "The flea pulled on a rope and up came a boat.\n",
      "I'll bet you can't guess \n",
      "what happened next.\n",
      "A flea family ran from \n",
      "the dog's little toe.\n",
      "They got into the boat and began to row.\n",
      "Once on the shore, they ran through the sand.\n",
      "Over a cookie in \n",
      "my left hand.\n",
      "Right to the hog, that's \n",
      "where they went.\n",
      "They found a new home with an unpleasant scent.\n",
      "As for the Dog, he's still riding that log.\n",
      "As for me-Ouch-I think \n",
      "I have a flea.\n",
      "Your Story Book!\n",
      "A book specially made, \n",
      "with you as the main hero \n",
      "or heroine!\n",
      "Personalised children’s gifts by www.monkeypen.com\n",
      "Advertisement\n",
      "A Dog On A Log is just \n",
      "a fun story for the young \n",
      "reader.\n",
      "\n",
      "It may impart a \n",
      "sense of rhyme and rhythm \n",
      "but is intended to evoke a \n",
      "smile.\n",
      "Published by\n",
      "Illustrated by\n",
      "Please share our books with \n",
      "your friends and family to \n",
      "support our mission.\n",
      "\n",
      "Thank you\n",
      "Please make a donation on Patreon to support Monkey Pen Free Book Project:\n",
      "On a beach by a tree, sat my family and me.Then shouted a hog, \"There's a Dog On A Log!!\"A Dog On A Log? Well, how can that be?He must be saving that big, frightening flea.Even that Dog On A Log was perplexed.The flea pulled on a rope and up came a boat.I'll bet you can't guess \n",
      "what happened next.A flea family ran from \n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import fitz\n",
    "from tkinter import filedialog\n",
    "import tkinter as tk\n",
    "import torch\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = ''\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc[page_num]\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "def generate_summary_with_chatgpt(text):\n",
    "    model_name = \"gpt2\"\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "    input_ids = tokenizer.encode(text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    \n",
    "    # Create attention mask\n",
    "    attention_mask = torch.ones(input_ids.shape, dtype=torch.long)\n",
    "\n",
    "    model.config.pad_token_id = tokenizer.eos_token_id\n",
    "    \n",
    "    summary_ids = model.generate(\n",
    "        input_ids,\n",
    "        max_length=600,\n",
    "        attention_mask=attention_mask,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        num_beams=4,\n",
    "        early_stopping=True\n",
    "    )\n",
    "\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "def format_summary(summary):\n",
    "    # Add line breaks between sentences or paragraphs\n",
    "    formatted_summary = summary.replace('. ', '.\\n\\n')\n",
    "    return formatted_summary\n",
    "\n",
    "def main():\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "\n",
    "    pdf_path = filedialog.askopenfilename(title=\"Select PDF file\", filetypes=[(\"PDF files\", \"*.pdf\")])\n",
    "\n",
    "    try:\n",
    "        pdf_text = extract_text_from_pdf(pdf_path)\n",
    "        summary = generate_summary_with_chatgpt(pdf_text)\n",
    "        \n",
    "        formatted_summary = format_summary(summary)\n",
    "\n",
    "        print(\"\\nGenerated Summary:\")\n",
    "        print(formatted_summary)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2eeb5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
